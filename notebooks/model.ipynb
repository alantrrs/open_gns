{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNS Implementation Details\n",
    "\n",
    "The model works by adopting a particle-based representation of the physical system. Physical dynamics are approximated by interactions among the particles. The objective of the model is to learn these interactions.\n",
    "\n",
    "## Input and output representations\n",
    "### Inputs\n",
    "Each particle's input state vector represents:\n",
    "- Position, $p_i^{t}$\n",
    "- A sequence of $C=5$ previous velocities. The velocity is calculated from the difference in position between consecutive time steps: $\\dot{p}^t=p^t-p^{t-1}$\n",
    "- Features that capture the static material properties (e.g. water, sand, rigid, etc..). The material is expressed as a particle feature, $a_i$, represented with a learned embedding vector of size 16.\n",
    "- The global properties of the system, $g$, include external forces and global material properties.\n",
    "- For datasets with fixed flat orthogonal walls, instead of adding boundary particles, a feature is added to each node indicating the vector distance to each wall, $d^{t}_i$. To maintain spatial transalation invariance, this distance is clipped to the connectivity radius $R$, achieving a similar effect to that of the boundary particles.\n",
    "\n",
    "The particle feature tensor looks as follows:\n",
    "$$x^{t}_i = [p^{t}_i,\\dot{p}^{t-C+1}_i,...,\\dot{p}^{t}_i,a_i, g, d^{t}_i]$$\n",
    "\n",
    "\n",
    "### Outputs\n",
    "The prediction targets for supervised learning are the per-particle average acceleration, $$\\ddot{p}^t_i=\\dot{p}^{t+1}-\\dot{p}^t=p^{t+1}-2p^{t}+p^{t-1}$$\n",
    "\n",
    "\n",
    "## Encoder\n",
    "The encoder embeds the particle-based state representation, $X$, as a latent graph $G_0=\\text{ENCODER}(X)$, where $G=(V,E,\\mathbf{u})$, $\\mathbf{v}_i\\in V$, and $\\mathbf{e}_{i,j}\\in E$.\n",
    "- The encoder constructs the graph structure $G^0$ by assignning a node to each particle and adding edges between particles within a connectivity radius, $R$. On each timestep the graph's edges are recomputed by a nearest neighbor algorithm, implemented by a standard kd-tree, to reflect the current particle positions.\n",
    "- The node embeddings, $\\mathbf{v}_i=\\varepsilon ^v(x_i)$, are learned functions of the particles' states.\n",
    "- The edge embeddings, $\\mathbf{e}_{i,j}=\\varepsilon^e(\\mathbf{r}_{i,j})$, are learned functions of the pairwise properties of the corresponding particles, $\\mathbf{r}_{i,j}$, e.g., displacement between their positions, spring constant, etc.\n",
    "- $\\varepsilon^v$ and $\\varepsilon^e$ as a multilayer perceptron, which encode node features and edge features into the latent vectors, $v_i$ and $e_{i,j}$, of size $128$.\n",
    "- The graph-level embedding, $\\mathbf{u}$, could represent global properties such as gravity and magnetic fields. Although, this is currently implemented as node level features instead.\n",
    "\n",
    "## Processor\n",
    "...\n",
    "\n",
    "## Decoder\n",
    "...\n",
    "\n",
    "## Noise\n",
    "...TODO...\n",
    "\n",
    "## Normalization\n",
    "...TODO...\n",
    "\n",
    "## Loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "class GNSDataset(InMemoryDataset):\n",
    "    def __init__(self, root, tranform=None, pre_transform=None):\n",
    "        super(GNSDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "    @propery\n",
    "    def raw_file_names(self):\n",
    "        return ['box_bath.hdf5']\n",
    "    \n",
    "    @propery\n",
    "    def processed_file_names(self):\n",
    "        return ['box_bath_graph_sequences.hdf5']\n",
    "    \n",
    "    def process(self):\n",
    "        # Read all positions & transform into features\n",
    "        f = h5py.File(self.raw_file_names[0],'r')\n",
    "        f.keys()\n",
    "        # TODO: Calculate relative positions\n",
    "        \n",
    "        # Calculate velocities\n",
    "        # Calculate distance to walls\n",
    "        # Get material properties vector\n",
    "        # Add global forces\n",
    "        # Make the tensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "f = h5py.File('box_bath.hdf5','r')\n",
    "\n",
    "for k in range(1): #f.get('rollouts').keys():\n",
    "    # Read positions\n",
    "    positions = np.array(f.get(f'rollouts/{k}/positions'))\n",
    "    # Calculate velocities\n",
    "    velocities = np.concatenate(([np.zeros(positions[0].shape)],\n",
    "                                positions[1:] - positions[0:-1]),axis=0)\n",
    "    # Calculate accelerations\n",
    "    accelerations = np.concatenate(([np.zeros(velocities[0].shape)],\n",
    "                                velocities[1:] - velocities[0:-1]),axis=0)\n",
    "    # Material properties (using one-hot encoding for now)\n",
    "    m = np.zeros((len(positions[0]), 2))\n",
    "    m[0:64] = [0,1] # First 64 particles are solid\n",
    "    m[64:] = [1,0]\n",
    "    # TODO: Global forces\n",
    "    # TODO: Distance to walls\n",
    "    x = []\n",
    "    y = accelerations[6:-1]\n",
    "    # Drop the first 5 and the last step since we don't have accurate velocities/accelerations\n",
    "    for t in range(6,len(positions)-1):\n",
    "        print(f'pos: {positions[t].shape}, m: {m.shape}, vels: {np.concatenate(velocities[t-5:t], axis=1).shape}')\n",
    "        xt = np.concatenate((positions[t], m, np.concatenate(velocities[t-5:t], axis=1)), axis=1)\n",
    "        print(f'xt {xt.shape}')\n",
    "        x.append(xt)\n",
    "    x = np.array(x)\n",
    "    print(f'X: {x.shape}, Y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p = np.arange(3*2).reshape(2, 3)\n",
    "m = np.arange(2*2).reshape(2, 2)\n",
    "v  = np.arange(3*2*5).reshape(5,2,3)\n",
    "print(f'p: {p.shape} m: {m.shape} v: {v.shape}')\n",
    "print(np.concatenate((p, m, np.concatenate(v, axis=1)),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Parameters for BoxBath:\n",
    "- Trajectory length: 150\n",
    "- Number of rollouts: Train/Validation/Test -> 2700/150/150\n",
    "- Connectivity radius: $R=0.08$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
