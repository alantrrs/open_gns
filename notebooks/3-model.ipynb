{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\=]-\n",
    ";?# GNS Implementation Details\n",
    "\n",
    "The model works by adopting a particle-based representation of the physical system. Physical dynamics are approximated by interactions among the particles. The objective of the model is to learn these interactions.\n",
    "\n",
    "## Encoder\n",
    "The encoder embeds the particle-based state representation, $X$, as a latent graph $G_0=\\text{ENCODER}(X)$, where $G=(V,E,\\mathbf{u})$, $\\mathbf{v}_i\\in V$, and $\\mathbf{e}_{i,j}\\in E$.\n",
    "- The encoder constructs the graph structure $G^0$ by assignning a node to each particle and adding edges between particles within a connectivity radius, $R$. On each timestep the graph's edges are recomputed by a nearest neighbor algorithm, implemented by a standard kd-tree, to reflect the current particle positions.\n",
    "- The node embeddings, $\\mathbf{v}_i=\\varepsilon ^v(x_i)$, are learned functions of the particles' states.\n",
    "- The edge embeddings, $\\mathbf{e}_{i,j}=\\varepsilon^e(\\mathbf{r}_{i,j})$, are learned functions of the pairwise properties of the corresponding particles, $\\mathbf{r}_{i,j}$, e.g., displacement between their positions, spring constant, etc.\n",
    "- $\\varepsilon^v$ and $\\varepsilon^e$ as a multilayer perceptron, which encode node features and edge features into the latent vectors, $v_i$ and $e_{i,j}$, of size $128$.\n",
    "- The graph-level embedding, $\\mathbf{u}$, could represent global properties such as gravity and magnetic fields. Although, this is currently implemented as node level features instead.\n",
    "- There are 2 variants of the encoder:\n",
    "    - In the absolute variant the input to the edge model $\\varepsilon^{e}$ is discarded, and $\\mathbf{e}^0_{i,j}$ is set to a trainable fixed bias vector instead.\n",
    "    - The relative encoder variant is designed to impose an inductive bias of invariance to absolute spatial location. The node model $\\varepsilon^{v}$ is forced to ignore $\\mathbf{p}_i$ information within $x_i$ by masking it out. The edge model $\\varepsilon^{e}$ is provided with the relative positional displacement, and it's magnitude,  $r_{i,j}=[(\\mathbf{p}_i-\\mathbf{p}_j),\\lVert\\mathbf{p}_i-\\mathbf{p}_j\\rVert]$\n",
    "\n",
    "\n",
    "## Neural network parameters\n",
    "- All MLPs have **2 hidden layers** with **ReLU** activations, followed by a non-activated output layer, each layer with size **128**.\n",
    "- All MLPs, except the output decoder, are followed by a **LayerNorm** layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "# setup autoreload\n",
    "%load_ext autoreload\n",
    "#%autoreload 2\n",
    "# Change working directory to root directory\n",
    "%cd \"/workspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting open_gns/models/encoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile open_gns/models/encoder.py\n",
    "\n",
    "import torch\n",
    "from torch.nn import Sequential, Linear, ReLU, LayerNorm\n",
    "from torch_geometric.nn import MetaLayer\n",
    "\n",
    "def make_mlp(input_size, hidden_size=128, output_size=128, layer_norm=True):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    layers = [\n",
    "        Linear(input_size, hidden_size),\n",
    "            ReLU(),\n",
    "            Linear(hidden_size, hidden_size),\n",
    "            ReLU(),\n",
    "            Linear(hidden_size, output_size),\n",
    "    ]\n",
    "    if layer_norm:\n",
    "        layers.append(LayerNorm(output_size))\n",
    "    return Sequential(*layers).to(device)\n",
    "\n",
    "class EdgeModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(EdgeModel, self).__init__()\n",
    "        self.edge_mlp = make_mlp(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        features = [src, dest] if edge_attr is None else [src, dest, edge_attr]\n",
    "        out = torch.cat(features, 1)\n",
    "        return self.edge_mlp(out)\n",
    "\n",
    "class NodeModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(NodeModel, self).__init__()\n",
    "        self.node_mlp = make_mlp(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # TODO: Do we need to combine with edge_attr?\n",
    "        return self.node_mlp(x)\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = MetaLayer(EdgeModel(2*input_size), NodeModel(input_size))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # TODO: The encoder needs to build the Graph\n",
    "        # otherwise the graph would need to be pre-built\n",
    "        return self.encoder(x, edge_index)\n",
    "\n",
    "    \n",
    "class RelativeEdgeModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=128):\n",
    "        super(RelativeEdgeModel, self).__init__()\n",
    "        self.edge_mlp = make_mlp(4, hidden_size)\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        distance = src[:,0:3] - dest[:,0:3]\n",
    "        magnitude = torch.norm(distance, dim=1, keepdim=True)\n",
    "        out = torch.cat([distance, magnitude], 1)\n",
    "        return self.edge_mlp(out)\n",
    "\n",
    "\n",
    "class RelativeNodeModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(RelativeNodeModel, self).__init__()\n",
    "        self.node_mlp = make_mlp(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        masked = x.clone()\n",
    "        masked[:,0:3] = 0\n",
    "        return self.node_mlp(x)\n",
    "\n",
    "    \n",
    "class RelativeEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size=128):\n",
    "        super(RelativeEncoder, self).__init__()\n",
    "        self.encoder = MetaLayer(RelativeEdgeModel(), RelativeNodeModel(input_size))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.encoder(x, edge_index)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2454, -0.7263,  0.2144,  0.0836],\n",
      "        [ 0.3430,  0.7757,  1.0537, -0.8873]])\n",
      "tensor([[0.8004],\n",
      "        [1.6177]])\n",
      "tensor([[-0.2454, -0.7263,  0.2144,  0.0836,  0.8004],\n",
      "        [ 0.3430,  0.7757,  1.0537, -0.8873,  1.6177]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,4)\n",
    "b = torch.norm(a,dim=1,keepdim=True)\n",
    "c = torch.cat([a,b], 1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 111683, Num node features: 25\n",
      "input_size: 25\n",
      "0 0 0 0\n",
      "torch.Size([1024, 128]) torch.Size([15440, 128])\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "# Testing the Encoder\n",
    "from open_gns.dataset import GNSDataset\n",
    "from open_gns.models.encoder import RelativeEncoder\n",
    "# Load dataset\n",
    "dataset = GNSDataset('./notebooks')\n",
    "print(f'Samples: {len(dataset)}, Num node features: {dataset.num_node_features}')\n",
    "data = dataset[0]\n",
    "input_size= dataset.num_node_features\n",
    "\n",
    "encoder = RelativeEncoder(input_size)\n",
    "data.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x, e, u = encoder(data.x.float(), data.edge_index)\n",
    "print(x.size(), e.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor\n",
    "The *PROCESSOR* performs $M$ rounds of learned message-passing over the latent graphs, $G^0, ..., G^M$. This is implemented by a stack of $M$ GNs with identical structure, MLPs as internal edge and node update functions, and either shared or unshared parameters. GNs are used without global features or global updates, and with a residual connection between the input and output latent node and edge attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting open_gns/models/processor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile open_gns/models/processor.py\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import MetaLayer\n",
    "from open_gns.models.encoder import EdgeModel, NodeModel\n",
    "\n",
    "class Processor(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size=128, M=10):\n",
    "        super(Processor, self).__init__()\n",
    "        self.GNs = torch.nn.ModuleList([])\n",
    "        for i in range(M):\n",
    "            GN = MetaLayer(EdgeModel(3*input_size), NodeModel(input_size))\n",
    "            self.GNs.append(GN) \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        for GN in self.GNs:\n",
    "            # TODO: Concatenate residuals instead?\n",
    "            # Keep residuals\n",
    "            node_residual = x\n",
    "            edge_residual = edge_attr\n",
    "            # Apply GN\n",
    "            x, edge_attr, u = GN(x, edge_index, edge_attr)\n",
    "            # Add residuals\n",
    "            x = x + node_residual\n",
    "            edge_attr = edge_attr + edge_residual\n",
    "        return x, edge_attr, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15440, 128])\n",
      "torch.Size([1024, 128]) torch.Size([15440, 128])\n"
     ]
    }
   ],
   "source": [
    "# Testing the processor\n",
    "from open_gns.models.processor import Processor\n",
    "\n",
    "processor = Processor(128)\n",
    "print(e.size())\n",
    "x, e, u = processor(x, data.edge_index, e)\n",
    "print(x.size(), e.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "The *DECODER* extracts dynamic information from the nodes of the final latent graph, $G^M$, produced by the *PROCESSOR*. The decoder's learned function, $\\delta^v$, is an MLP. After the *DECODER*, the future position and velocity are updated using an Euler integrator, so the $\\mathbf{y}_i$ corresponds to accelerations, $\\ddot{p}^t_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting open_gns/models/decoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile open_gns/models/decoder.py\n",
    "\n",
    "import torch\n",
    "from open_gns.models.encoder import make_mlp\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = make_mlp(input_size, output_size=3, layer_norm=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3])\n"
     ]
    }
   ],
   "source": [
    "from open_gns.models.decoder import Decoder\n",
    "# Test the decoder\n",
    "decorder = Decoder(input_size=x.size(1))\n",
    "out = decorder(x)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting open_gns/models/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile open_gns/models/__init__.py\n",
    "import torch\n",
    "from open_gns.models.encoder import RelativeEncoder\n",
    "from open_gns.models.processor import Processor\n",
    "from open_gns.models.decoder import Decoder\n",
    "\n",
    "class EncodeProcessDecode(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128):\n",
    "        super(EncodeProcessDecode, self).__init__()\n",
    "        self.encoder = RelativeEncoder(input_size)\n",
    "        self.processor = Processor(hidden_size)\n",
    "        self.decoder = Decoder(hidden_size)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x, edge_attr, _ = self.encoder(x, edge_index)\n",
    "        x, edge_attr, _ = self.processor(x, edge_index, edge_attr)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-b6ba409d1819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncodeProcessDecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-39e1f02e7cd9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, hidden_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncodeProcessDecode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRelativeEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/open_gns/models/encoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, output_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRelativeEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRelativeEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetaLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRelativeEdgeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRelativeNodeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "gns = EncodeProcessDecode(input_size)\n",
    "y = gns(data.x.float(), data.edge_index)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Parameters for BoxBath:\n",
    "\n",
    "- Connectivity radius: $R=0.08$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
